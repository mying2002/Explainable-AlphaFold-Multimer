{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook for processing and pyMol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data step 1: grab PDB file paths for local\n",
    "returns complex_id_pdb_dict mapping [str1_id]\\_[str2_id] to pdb\\_file\\_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdb stuff\n",
    "garbage_pdb_path = '../garbage_out/multimer_all_pdb/' # relative\n",
    "pdb_files_list = os.listdir(garbage_pdb_path)\n",
    "\n",
    "\n",
    "# config file stuff\n",
    "config_file_path = '../config_files/multimer_config.txt' # relative\n",
    "config_file_df = pd.read_csv(config_file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq1_id</th>\n",
       "      <th>seq2_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5oxz_A</td>\n",
       "      <td>5oxz_B</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ytq_A</td>\n",
       "      <td>5ytq_B</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6dm9_A</td>\n",
       "      <td>6dm9_B</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6dvu_A</td>\n",
       "      <td>6dvu_B</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6eby_A</td>\n",
       "      <td>6eby_B</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seq1_id seq2_id  count\n",
       "0  5oxz_A  5oxz_B    139\n",
       "1  5ytq_A  5ytq_B    155\n",
       "2  6dm9_A  6dm9_B    157\n",
       "3  6dvu_A  6dvu_B    167\n",
       "4  6eby_A  6eby_B    159"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file_counts_df = config_file_df.groupby(['seq1_id','seq2_id']).size().reset_index().rename(columns={0:'count'}) # should match output results; already checked in retry_failed_jobs.ipynb\n",
    "config_file_counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dictionary matching metadata to PDB file name\n",
    "[str1_id]\\_[str2_id] : pdb\\_file\\_name\n",
    "\n",
    "Note: only care about unperturbed multimers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_id_pdb_dict = {}\n",
    "\n",
    "for index, row in config_file_counts_df.iterrows():\n",
    "    # only care unperturbed rows\n",
    "    complex_id = row['seq1_id'] + '_' + row['seq2_id']\n",
    "    baseline_complex_id = row['seq1_id'] + '_' + row['seq2_id'] + '_0' # 0 finds the ones where nothing is deleted\n",
    "    # metadata_str = '5oxz_A_5oxz_B_1_1_'\n",
    "    # print(metadata_str)\n",
    "\n",
    "    for pdb_file in pdb_files_list:\n",
    "        # if pdb file corresponds to a baseline run (no perturbations)\n",
    "        if baseline_complex_id in pdb_file:\n",
    "            complex_id_pdb_dict[complex_id] = pdb_file\n",
    "            # print(pdb_file)\n",
    "        \n",
    "    # break\n",
    "\n",
    "len(complex_id_pdb_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy and save useful PDB files into new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  for copying files\n",
    "import shutil \n",
    "\n",
    "dst_path = '../selected_pdb_files/multimer_pdb/'\n",
    "\n",
    "for pdb_file in complex_id_pdb_dict.values():\n",
    "    src_file = garbage_pdb_path + pdb_file # local path\n",
    "    dst_file = dst_path + pdb_file\n",
    "\n",
    "    # copy file\n",
    "    # shutil.copyfile(src_file, dst_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data step 2: process outputs from AlphaFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq1_id</th>\n",
       "      <th>seq2_id</th>\n",
       "      <th>seq1</th>\n",
       "      <th>seq2</th>\n",
       "      <th>which_seq</th>\n",
       "      <th>delete_index</th>\n",
       "      <th>mean_pLDDT_score</th>\n",
       "      <th>pTM_score</th>\n",
       "      <th>ipTM_score</th>\n",
       "      <th>complex_id</th>\n",
       "      <th>baseline_mean_pLDDT_score</th>\n",
       "      <th>baseline_pTM_score</th>\n",
       "      <th>baseline_ipTM_score</th>\n",
       "      <th>delta_mean_pLDDT_score</th>\n",
       "      <th>delta_pTM_score</th>\n",
       "      <th>delta_ipTM_score</th>\n",
       "      <th>pdb_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6owd_A</td>\n",
       "      <td>6owd_B</td>\n",
       "      <td>XQIARLQRQIRALQRQNARLQRQIRALQWX</td>\n",
       "      <td>XQIARLQRQIRALQRQNARLQRQIRALQWX</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>95.6250</td>\n",
       "      <td>0.782227</td>\n",
       "      <td>0.752930</td>\n",
       "      <td>6owd_A_6owd_B</td>\n",
       "      <td>95.25</td>\n",
       "      <td>0.783691</td>\n",
       "      <td>0.754395</td>\n",
       "      <td>-0.3750</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>6owd_A_6owd_B_0_1_9c291_unrelaxed_rank_001_alp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6owd_A</td>\n",
       "      <td>6owd_B</td>\n",
       "      <td>XQIARLQRQIRALQRQNARLQRQIRALQWX</td>\n",
       "      <td>XQIARLQRQIRALQRQNARLQRQIRALQWX</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>93.1250</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.675293</td>\n",
       "      <td>6owd_A_6owd_B</td>\n",
       "      <td>95.25</td>\n",
       "      <td>0.783691</td>\n",
       "      <td>0.754395</td>\n",
       "      <td>2.1250</td>\n",
       "      <td>0.053223</td>\n",
       "      <td>0.079102</td>\n",
       "      <td>6owd_A_6owd_B_0_1_9c291_unrelaxed_rank_001_alp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6owd_A</td>\n",
       "      <td>6owd_B</td>\n",
       "      <td>XQIARLQRQIRALQRQNARLQRQIRALQWX</td>\n",
       "      <td>XQIARLQRQIRALQRQNARLQRQIRALQWX</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>95.5625</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>0.743164</td>\n",
       "      <td>6owd_A_6owd_B</td>\n",
       "      <td>95.25</td>\n",
       "      <td>0.783691</td>\n",
       "      <td>0.754395</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.011230</td>\n",
       "      <td>6owd_A_6owd_B_0_1_9c291_unrelaxed_rank_001_alp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6owd_A</td>\n",
       "      <td>6owd_B</td>\n",
       "      <td>XQIARLQRQIRALQRQNARLQRQIRALQWX</td>\n",
       "      <td>XQIARLQRQIRALQRQNARLQRQIRALQWX</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>95.2500</td>\n",
       "      <td>0.770996</td>\n",
       "      <td>0.739746</td>\n",
       "      <td>6owd_A_6owd_B</td>\n",
       "      <td>95.25</td>\n",
       "      <td>0.783691</td>\n",
       "      <td>0.754395</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>6owd_A_6owd_B_0_1_9c291_unrelaxed_rank_001_alp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6owd_A</td>\n",
       "      <td>6owd_B</td>\n",
       "      <td>XQIARLQRQIRALQRQNARLQRQIRALQWX</td>\n",
       "      <td>XQIARLQRQIRALQRQNARLQRQIRALQWX</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>95.1875</td>\n",
       "      <td>0.771973</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>6owd_A_6owd_B</td>\n",
       "      <td>95.25</td>\n",
       "      <td>0.783691</td>\n",
       "      <td>0.754395</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>6owd_A_6owd_B_0_1_9c291_unrelaxed_rank_001_alp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  seq1_id seq2_id                            seq1  \\\n",
       "0  6owd_A  6owd_B  XQIARLQRQIRALQRQNARLQRQIRALQWX   \n",
       "1  6owd_A  6owd_B  XQIARLQRQIRALQRQNARLQRQIRALQWX   \n",
       "2  6owd_A  6owd_B  XQIARLQRQIRALQRQNARLQRQIRALQWX   \n",
       "3  6owd_A  6owd_B  XQIARLQRQIRALQRQNARLQRQIRALQWX   \n",
       "4  6owd_A  6owd_B  XQIARLQRQIRALQRQNARLQRQIRALQWX   \n",
       "\n",
       "                             seq2  which_seq  delete_index  mean_pLDDT_score  \\\n",
       "0  XQIARLQRQIRALQRQNARLQRQIRALQWX          1             2           95.6250   \n",
       "1  XQIARLQRQIRALQRQNARLQRQIRALQWX          1             5           93.1250   \n",
       "2  XQIARLQRQIRALQRQNARLQRQIRALQWX          1             3           95.5625   \n",
       "3  XQIARLQRQIRALQRQNARLQRQIRALQWX          1             4           95.2500   \n",
       "4  XQIARLQRQIRALQRQNARLQRQIRALQWX          2             3           95.1875   \n",
       "\n",
       "   pTM_score  ipTM_score     complex_id  baseline_mean_pLDDT_score  \\\n",
       "0   0.782227    0.752930  6owd_A_6owd_B                      95.25   \n",
       "1   0.730469    0.675293  6owd_A_6owd_B                      95.25   \n",
       "2   0.775391    0.743164  6owd_A_6owd_B                      95.25   \n",
       "3   0.770996    0.739746  6owd_A_6owd_B                      95.25   \n",
       "4   0.771973    0.742188  6owd_A_6owd_B                      95.25   \n",
       "\n",
       "   baseline_pTM_score  baseline_ipTM_score  delta_mean_pLDDT_score  \\\n",
       "0            0.783691             0.754395                 -0.3750   \n",
       "1            0.783691             0.754395                  2.1250   \n",
       "2            0.783691             0.754395                 -0.3125   \n",
       "3            0.783691             0.754395                  0.0000   \n",
       "4            0.783691             0.754395                  0.0625   \n",
       "\n",
       "   delta_pTM_score  delta_ipTM_score  \\\n",
       "0         0.001465          0.001465   \n",
       "1         0.053223          0.079102   \n",
       "2         0.008301          0.011230   \n",
       "3         0.012695          0.014648   \n",
       "4         0.011719          0.012207   \n",
       "\n",
       "                                            pdb_file  \n",
       "0  6owd_A_6owd_B_0_1_9c291_unrelaxed_rank_001_alp...  \n",
       "1  6owd_A_6owd_B_0_1_9c291_unrelaxed_rank_001_alp...  \n",
       "2  6owd_A_6owd_B_0_1_9c291_unrelaxed_rank_001_alp...  \n",
       "3  6owd_A_6owd_B_0_1_9c291_unrelaxed_rank_001_alp...  \n",
       "4  6owd_A_6owd_B_0_1_9c291_unrelaxed_rank_001_alp...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) grab results\n",
    "multimer_output_df = pd.read_csv('../deletion_perturb_out/multimer_output.csv')\n",
    "\n",
    "# (2) want dataframe with metadata_id full_seq which_seq delete_index all_scores\n",
    "multimer_results_df = multimer_output_df\n",
    "multimer_results_df['complex_id'] = multimer_results_df['seq1_id'] + '_' + multimer_results_df['seq2_id']\n",
    "\n",
    "# new baseline columns\n",
    "for index, row in multimer_results_df.iterrows():\n",
    "    if row['which_seq'] == 0:\n",
    "        curr_complex_id = row['complex_id']\n",
    "        baseline_mean_pLDDT_score = row['mean_pLDDT_score']\n",
    "        baseline_pTM_score = row['pTM_score']\n",
    "        baseline_ipTM_score = row['ipTM_score']\n",
    "\n",
    "        is_curr_complex_id = multimer_results_df['complex_id'] == curr_complex_id\n",
    "        multimer_results_df.loc[is_curr_complex_id, 'baseline_mean_pLDDT_score'] = baseline_mean_pLDDT_score\n",
    "        multimer_results_df.loc[is_curr_complex_id, 'baseline_pTM_score'] = baseline_pTM_score\n",
    "        multimer_results_df.loc[is_curr_complex_id, 'baseline_ipTM_score'] = baseline_ipTM_score\n",
    "\n",
    "# compute delta scores --> high delta = high score loss upon deletion = important. \n",
    "multimer_results_df['delta_mean_pLDDT_score'] = multimer_results_df['baseline_mean_pLDDT_score'] - multimer_results_df['mean_pLDDT_score']\n",
    "multimer_results_df['delta_pTM_score'] = multimer_results_df['baseline_pTM_score'] - multimer_results_df['pTM_score']\n",
    "multimer_results_df['delta_ipTM_score'] = multimer_results_df['baseline_ipTM_score'] - multimer_results_df['ipTM_score']\n",
    "\n",
    "# add pdb file names\n",
    "multimer_results_df['pdb_file'] = multimer_results_df['complex_id'].map(complex_id_pdb_dict)\n",
    "\n",
    "# check results\n",
    "multimer_results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "# multimer_results_df.to_csv('../deletion_perturb_out/processed_multimer_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monomer ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "config_file_path = '../config_files/monomer_config.txt'\n",
    "csv_dir_path = '../garbage_out/monomer_all_csv'\n",
    "pdb_dir_path = '../garbage_out/monomer_all_pdb'\n",
    "\n",
    "config_file = pd.read_csv(config_file_path, sep='\\t')\n",
    "\n",
    "full_mon_sequences = config_file[config_file.delete_index == -1].seq.to_numpy()\n",
    "\n",
    "csv_file_list = os.listdir(csv_dir_path)\n",
    "\n",
    "pdb_file_list = os.listdir(pdb_dir_path)\n",
    "\n",
    "full_seq_pdb_dict = {}\n",
    "\n",
    "for full_seq in full_mon_sequences:\n",
    "    seq_prefix = full_seq[:20]\n",
    "    candidate_csvs = [csv for csv in csv_file_list if seq_prefix in csv]\n",
    "    for cand_csv in candidate_csvs:\n",
    "        cur_cand_path = os.path.join(csv_dir_path, cand_csv)\n",
    "        cur_id = ''\n",
    "        cur_seq = ''\n",
    "        with open(cur_cand_path) as cur_csv:\n",
    "\n",
    "            for line in cur_csv:\n",
    "                # Skip header line\n",
    "                if line[:2] == 'id':\n",
    "                    continue\n",
    "                else:\n",
    "                    line_split = line.split(sep=',')\n",
    "                    cur_id = line_split[0]\n",
    "                    cur_seq = line_split[1]\n",
    "\n",
    "        if cur_seq == full_seq:\n",
    "            matching_pdbs = [pdb for pdb in pdb_file_list if cur_id in pdb]\n",
    "            # If matching_pdbs is empty move on\n",
    "            if not matching_pdbs:\n",
    "                continue\n",
    "            else:\n",
    "                if len(matching_pdbs) != 1:\n",
    "                    print(len(matching_pdbs))\n",
    "                matching_pdb = matching_pdbs[0]\n",
    "                full_seq_pdb_dict[full_seq] = matching_pdb\n",
    "                break\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy each pdb file in the dictionary to a desired directory for later use\n",
    "\n",
    "source_dir = '../garbage_out/monomer_all_pdb'\n",
    "dest_dir = '../selected_pdb_files/monomer_pdb'\n",
    "\n",
    "import shutil\n",
    "for pdb_file in list(full_seq_pdb_dict.values()):\n",
    "    source_path = os.path.join(source_dir, pdb_file)\n",
    "    dest_path = os.path.join(dest_dir, pdb_file)\n",
    "    shutil.copyfile(source_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume we have these variables (CHANGE NAMES HERE AND DOWN THE LINE):\n",
    "# full_seq_pdb_dict maps full sequences to names of pdb files\n",
    "matched_csv_df = pd.read_csv('../matching_deletion_perturb_out/matching_monomer_output.csv') # contains ArrayTaskID, seq, delete_index, mean_pLDDT_score, pTM_score\n",
    "\n",
    "# goal: master csv that contains column with (baseline) pdb file name and delta scores\n",
    "processed_monomer_df = matched_csv_df\n",
    "\n",
    "for index, row in processed_monomer_df.iterrows():\n",
    "    # find baseline rows; use its scores as baseline scores\n",
    "    if row['delete_index'] == -1:\n",
    "        baseline_mean_pLDDT_score = row['mean_pLDDT_score']\n",
    "        baseline_pTM_score = row['pTM_score']\n",
    "\n",
    "        # find rows with same full seq\n",
    "        curr_full_seq = row['seq']\n",
    "        is_curr_full_seq = processed_monomer_df['seq'] == curr_full_seq \n",
    "\n",
    "        # write in baseline scores\n",
    "        processed_monomer_df.loc[is_curr_full_seq, 'baseline_mean_pLDDT_score'] = baseline_mean_pLDDT_score\n",
    "        processed_monomer_df.loc[is_curr_full_seq, 'baseline_pTM_score'] = baseline_pTM_score\n",
    "\n",
    "# compute delta scores\n",
    "processed_monomer_df['delta_mean_pLDDT_score'] = processed_monomer_df['baseline_mean_pLDDT_score'] - processed_monomer_df['mean_pLDDT_score']\n",
    "processed_monomer_df['delta_pTM_score'] = processed_monomer_df['baseline_pTM_score'] - processed_monomer_df['pTM_score']\n",
    "\n",
    "# add pdb file names\n",
    "processed_monomer_df['pdb_file'] = processed_monomer_df['seq'].map(full_seq_pdb_dict) # first variable\n",
    "\n",
    "# check results\n",
    "processed_monomer_df.head()\n",
    "\n",
    "# save file when good\n",
    "#processed_monomer_df.to_csv('../processed_deletion_perturb_out/processed_monomer_output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e91ef92c3dc3d980f4c8f3e32d5d256dbadfe73048aa6d5ed1e7a077429687dc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.14 64-bit ('cpsc471': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
