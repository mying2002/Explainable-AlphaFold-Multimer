{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook to check completeness (Antibody-Antigen) and fill in missing data (if any)\n",
    "Certain jobs (from a batch) on Grace can occasionally fail due to HTTP timeouts when using the mmseqs2 API. This jupyter notebook looks to see if all jobs were successfull. If not, then it identifies missing jobs and creates a new config file to fill in the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: check if data is complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab outputs from Grace (scp to local first, then read csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3483, 5)\n",
      "(3469, 10)\n"
     ]
    }
   ],
   "source": [
    "# --- check path; csv outputs from grace --- #\n",
    "AA_monomer_outputs_df = pd.read_csv('../deletion_perturb_out/AA_monomer_output.csv') # csv output from Grace\n",
    "AA_multimer_outputs_df = pd.read_csv('../deletion_perturb_out/AA_multimer_output.csv') # csv output from Grace\n",
    "\n",
    "AA_multimer_outputs_df['complex_id'] = AA_multimer_outputs_df['seq1_id'] + '_' + AA_multimer_outputs_df['seq2_id'] # add this\n",
    "\n",
    "print(AA_monomer_outputs_df.shape) # want 3481 rows\n",
    "print(AA_multimer_outputs_df.shape) # want 3466 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual inspection of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>delete_index</th>\n",
       "      <th>mean_pLDDT_score</th>\n",
       "      <th>pTM_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>609375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     seq_id  seq  delete_index  mean_pLDDT_score  pTM_score\n",
       "446  609375  NaN           NaN               NaN        NaN\n",
       "647       5  NaN           NaN               NaN        NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = AA_monomer_outputs_df[AA_monomer_outputs_df.isnull().any(axis=1)]\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Test 1]: compare counts with expected outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       complex_id  count_x  count_y\n",
      "0   7a0w_A_7a0w_B      226      226\n",
      "1   7fcq_A_7fcq_B      239      239\n",
      "2   7mdp_A_7mdp_B      232      232\n",
      "3   7phu_A_7phu_B      231      231\n",
      "4   7qez_A_7qez_B      233      233\n",
      "5   7rew_A_7rew_B      229      229\n",
      "6   7s0x_A_7s0x_B      227      227\n",
      "7   7sd5_A_7sd5_B      241      241\n",
      "8   7t0l_A_7t0l_B      228      228\n",
      "9   7tp4_A_7tp4_B      233      233\n",
      "10  7wbz_A_7wbz_B      226      226\n",
      "11  7wvg_A_7wvg_B      232      232\n",
      "12  7xy8_A_7xy8_B      225      225\n",
      "13  7z0x_A_7z0x_B      238      238\n",
      "14  8be1_A_8be1_B      226      226\n"
     ]
    }
   ],
   "source": [
    "# get counts for each baseline input sequence\n",
    "AA_monomer_counts = AA_monomer_outputs_df.groupby(['seq_id']).size().reset_index(name='count')\n",
    "\n",
    "AA_multimer_counts = AA_multimer_outputs_df\n",
    "AA_multimer_counts = AA_multimer_counts.groupby(['complex_id']).size().reset_index(name='count')\n",
    "\n",
    "# get expected counts\n",
    "AA_monomer_config_df = pd.read_csv('../config_files/AA_monomer_config.txt', sep='\\t') # relative\n",
    "AA_monomer_expected_counts = AA_monomer_config_df.groupby(['seq_id']).size().reset_index(name='count')\n",
    "\n",
    "AA_multimer_config_df = pd.read_csv('../config_files/AA_multimer_config.txt', sep='\\t') # relative\n",
    "AA_multimer_config_df['complex_id'] = AA_multimer_config_df['seq1_id'] + '_' + AA_multimer_config_df['seq2_id']\n",
    "AA_multimer_expected_counts = AA_multimer_config_df.groupby(['complex_id']).size().reset_index(name='count')\n",
    "\n",
    "AA_monomer_merged_counts = pd.merge(AA_monomer_counts, AA_monomer_expected_counts, on=['seq_id'], how='outer')\n",
    "AA_multimer_merged_counts = pd.merge(AA_multimer_counts, AA_multimer_expected_counts, on=['complex_id'], how='outer')\n",
    "\n",
    "# manual inspection\n",
    "# print(AA_monomer_merged_counts)\n",
    "# print(AA_multimer_merged_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Test 2]: left join outputs onto expected to find matching/missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3481, 6)\n",
      "(3466, 11)\n",
      "(0, 6)\n",
      "(0, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArrayTaskID</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>delete_index</th>\n",
       "      <th>mean_pLDDT_score</th>\n",
       "      <th>pTM_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ArrayTaskID, seq_id, seq, delete_index, mean_pLDDT_score, pTM_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join outputs onto the expected df\n",
    "AA_monomer_left_join_df = pd.merge(AA_monomer_config_df, AA_monomer_outputs_df, on=['seq_id', 'seq', 'delete_index'], how='left') \n",
    "AA_multimer_left_join_df = pd.merge(AA_multimer_config_df, AA_multimer_outputs_df, on=['complex_id', 'seq1_id', 'seq2_id', 'seq1', 'seq2', 'which_seq', 'delete_index'], how='left') \n",
    "\n",
    "# sub dataframe of matching data\n",
    "AA_monomer_matching_df = AA_monomer_left_join_df[~AA_monomer_left_join_df.isnull().any(axis=1)]\n",
    "AA_multimer_matching_df = AA_multimer_left_join_df[~AA_multimer_left_join_df.isnull().any(axis=1)]\n",
    "\n",
    "print(AA_monomer_matching_df.shape)\n",
    "print(AA_multimer_matching_df.shape)\n",
    "\n",
    "# sub dataframe of missing data\n",
    "AA_monomer_missing_df = AA_monomer_left_join_df[AA_monomer_left_join_df.isnull().any(axis=1)]\n",
    "print(AA_monomer_missing_df.shape)\n",
    "AA_multimer_missing_df = AA_multimer_left_join_df[AA_multimer_left_join_df.isnull().any(axis=1)]\n",
    "print(AA_multimer_missing_df.shape)\n",
    "\n",
    "# print(AA_monomer_missing_df) # if empty, then all data matches!\n",
    "AA_monomer_missing_df.head()\n",
    "# AA_multimer_missing_df.head()\n",
    "\n",
    "# temp save to local to inspect\n",
    "# AA_monomer_missing_df.to_csv('find_AA_round1_missing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: if missing data, create new config file for Grace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save missing data as a \"to fill in\" config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_copies = 1 # run each missing job once\n",
    "\n",
    "# --- fill monomer --- #\n",
    "fill_AA_monomer_df = pd.DataFrame({})\n",
    "for _ in range(n_copies):\n",
    "    fill_AA_monomer_df = pd.concat([fill_AA_monomer_df, AA_monomer_missing_df], ignore_index=True)\n",
    "\n",
    "fill_AA_monomer_df = fill_AA_monomer_df.drop(['mean_pLDDT_score', 'pTM_score'], axis=1)\n",
    "fill_AA_monomer_df = fill_AA_monomer_df.reset_index(drop=True)\n",
    "fill_AA_monomer_df['ArrayTaskID'] = fill_AA_monomer_df.index + 1 # overwrites ArrayTaskID\n",
    "\n",
    "# save to local\n",
    "# fill_AA_monomer_df.to_csv('config_files/fill2_AA_monomer_config.txt', sep='\\t', index=False) # CAN CHANGE FILE NAME/PATH\n",
    "\n",
    "\n",
    "# --- fill multimer --- #\n",
    "fill_AA_multimer_df = pd.DataFrame({})\n",
    "for _ in range(n_copies):\n",
    "    fill_AA_multimer_df = pd.concat([fill_AA_multimer_df, AA_multimer_missing_df], ignore_index=True)\n",
    "\n",
    "fill_AA_multimer_df = fill_AA_multimer_df.drop(['mean_pLDDT_score', 'pTM_score', 'ipTM_score', 'complex_id'], axis=1)\n",
    "fill_AA_multimer_df = fill_AA_multimer_df.reset_index(drop=True)\n",
    "fill_AA_multimer_df['ArrayTaskID'] = fill_AA_multimer_df.index + 1 # overwrites ArrayTaskID\n",
    "\n",
    "# save to local\n",
    "# fill_AA_multimer_df.to_csv('config_files/fill1_AA_multimer_config.txt', sep='\\t', index=False) # CAN CHANGE FILE NAME/PATH\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArrayTaskID</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>delete_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ArrayTaskID, seq_id, seq, delete_index]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_AA_monomer_df\n",
    "# fill_AA_multimer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When done, save completed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- save matching data (remove weird stuff) --- #\n",
    "# AA_monomer_matching_df.to_csv('../matching_perturb_out/matching_AA_monomer_output.csv', index=False) \n",
    "# AA_multimer_matching_df.to_csv('../matching_perturb_out/matching_AA_multimer_output.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e91ef92c3dc3d980f4c8f3e32d5d256dbadfe73048aa6d5ed1e7a077429687dc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.14 64-bit ('cpsc471': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
